# å®ç°è®¡åˆ’ - é˜¶æ®µ 6ï¼šå®Œæ•´æµç¨‹ + æ”¶å°¾

> ç‰ˆæœ¬ï¼š1.0
> æ›´æ–°æ—¥æœŸï¼š2026-02-07

## é˜¶æ®µç›®æ ‡

å®ç°æ‰“æ–­åŠŸèƒ½ã€é™é»˜æ£€æµ‹ä¸è€³æœµé—ªåŠ¨ã€ä¼šè¯å­˜å‚¨ï¼ˆlocalStorageï¼‰ï¼Œå®Œæˆç«¯åˆ°ç«¯å®Œæ•´æµç¨‹æµ‹è¯•ï¼Œç¡®ä¿æ‰€æœ‰åŠŸèƒ½æ­£å¸¸åä½œã€‚

**å‰ç½®æ¡ä»¶ï¼š** é˜¶æ®µ 5ï¼ˆTTS + åŒæ­¥æ’­æ”¾ï¼‰å·²å®Œæˆ

---

## 1. ä»»åŠ¡æ¸…å•

| åºå· | ä»»åŠ¡ | ç±»å‹ | å¯å•å…ƒæµ‹è¯• |
|------|------|------|-----------|
| 6.1 | å®ç°æ‰“æ–­åŠŸèƒ½ | å‰ç«¯+åç«¯ | âœ“ |
| 6.2 | å®ç°é™é»˜æ£€æµ‹ | å‰ç«¯ | âœ“ |
| 6.3 | å®ç°è€³æœµå›¾æ ‡é—ªåŠ¨ | å‰ç«¯ | âœ“ |
| 6.4 | å®ç°ä¼šè¯å­˜å‚¨ï¼ˆlocalStorageï¼‰ | å‰ç«¯ | âœ“ |
| 6.5 | é¡µé¢åˆ·æ–°æ¢å¤ä¼šè¯ | å‰ç«¯ | âœ“ |
| 6.6 | ç«¯åˆ°ç«¯å®Œæ•´æµ‹è¯• | æµ‹è¯• | - |
| 6.7 | é”™è¯¯å¤„ç†å®Œå–„ | å‰ç«¯+åç«¯ | âœ“ |

---

## 2. è¯¦ç»†ä»»åŠ¡è¯´æ˜

### 2.1 å®ç°æ‰“æ–­åŠŸèƒ½

**åŠŸèƒ½æè¿°ï¼š**
- ç”¨æˆ·åœ¨ AI æ’­æ”¾è¯­éŸ³æ—¶å¼€å§‹è¯´è¯
- å‰ç«¯ç«‹å³åœæ­¢éŸ³é¢‘æ’­æ”¾ï¼Œæ¸…ç©ºæ’­æ”¾é˜Ÿåˆ—
- å‘é€ `interrupt` æ¶ˆæ¯ç»™åç«¯
- åç«¯åœæ­¢ LLM/TTS å¤„ç†ï¼Œè¿”å› `tts_end`
- å¼€å§‹æ–°ä¸€è½® ASR è¯†åˆ«

#### 2.1.1 å‰ç«¯æ‰“æ–­æ£€æµ‹

**æ–‡ä»¶ï¼š** `frontend/src/hooks/useInterrupt.ts`

```typescript
import { useCallback, useRef } from 'react';
import { useWebSocket } from './useWebSocket';
import { useAudioPlayer } from './useAudioPlayer';

interface UseInterruptReturn {
  triggerInterrupt: () => void;
  isInterrupting: boolean;
}

export const useInterrupt = (): UseInterruptReturn => {
  const { sendMessage } = useWebSocket();
  const { clear: clearAudioQueue, isPlaying } = useAudioPlayer();
  const isInterruptingRef = useRef(false);

  const triggerInterrupt = useCallback(() => {
    if (!isPlaying || isInterruptingRef.current) {
      return;
    }

    isInterruptingRef.current = true;

    // 1. ç«‹å³åœæ­¢éŸ³é¢‘æ’­æ”¾
    clearAudioQueue();

    // 2. å‘é€æ‰“æ–­æ¶ˆæ¯
    sendMessage({
      type: 'interrupt',
      data: {}
    });

    // é‡ç½®æ ‡è®°ï¼ˆå»¶è¿Ÿï¼Œé¿å…é‡å¤è§¦å‘ï¼‰
    setTimeout(() => {
      isInterruptingRef.current = false;
    }, 500);
  }, [isPlaying, clearAudioQueue, sendMessage]);

  return {
    triggerInterrupt,
    isInterrupting: isInterruptingRef.current,
  };
};
```

#### 2.1.2 å‰ç«¯å½•éŸ³æ—¶æ£€æµ‹æ‰“æ–­

**æ–‡ä»¶ï¼š** `frontend/src/hooks/useAudioRecorder.ts`ï¼ˆæ›´æ–°ï¼‰

```typescript
import { useInterrupt } from './useInterrupt';

export const useAudioRecorder = () => {
  const { triggerInterrupt } = useInterrupt();
  const { isPlaying } = useAudioPlayer();

  // ... å·²æœ‰ä»£ç  ...

  const onAudioData = useCallback((pcmData: Int16Array) => {
    // æ£€æµ‹æ˜¯å¦æœ‰æœ‰æ•ˆè¯­éŸ³ï¼ˆç®€å•é˜ˆå€¼æ£€æµ‹ï¼‰
    const hasVoice = detectVoice(pcmData);

    if (hasVoice && isPlaying) {
      // AI æ­£åœ¨æ’­æ”¾æ—¶ç”¨æˆ·è¯´è¯ï¼Œè§¦å‘æ‰“æ–­
      triggerInterrupt();
    }

    // å‘é€éŸ³é¢‘æ•°æ®
    sendAudioData(pcmData);
  }, [isPlaying, triggerInterrupt]);

  return {
    // ...
  };
};

// ç®€å•çš„è¯­éŸ³æ£€æµ‹ï¼ˆåŸºäºéŸ³é‡é˜ˆå€¼ï¼‰
function detectVoice(pcmData: Int16Array, threshold = 500): boolean {
  let sum = 0;
  for (let i = 0; i < pcmData.length; i++) {
    sum += Math.abs(pcmData[i]);
  }
  const average = sum / pcmData.length;
  return average > threshold;
}
```

#### 2.1.3 åç«¯æ‰“æ–­å¤„ç†

**æ–‡ä»¶ï¼š** `backend/api/websocket.py`ï¼ˆæ›´æ–°ï¼‰

```python
class WebSocketHandler:
    def __init__(self, websocket: WebSocket):
        # ... å·²æœ‰ä»£ç  ...
        self.is_processing = False
        self.should_interrupt = False

    async def handle_message(self, message: dict):
        msg_type = message.get("type")

        if msg_type == "interrupt":
            await self._handle_interrupt()
        # ... å…¶ä»–æ¶ˆæ¯å¤„ç† ...

    async def _handle_interrupt(self):
        """å¤„ç†æ‰“æ–­è¯·æ±‚"""
        self.should_interrupt = True

        # å‘é€ tts_end è¡¨ç¤ºå½“å‰å›å¤ç»“æŸ
        await self.send_message({
            "type": "tts_end",
            "data": {"full_text": "", "interrupted": True}
        })

    async def on_asr_complete(self, final_text: str):
        """ASR è¯†åˆ«å®Œæˆå›è°ƒï¼ˆæ›´æ–°ï¼‰"""
        # é‡ç½®æ‰“æ–­æ ‡è®°
        self.should_interrupt = False
        self.is_processing = True

        # ... ASR å¤„ç† ...

        # æµå¼å¤„ç†ï¼ˆæ£€æŸ¥æ‰“æ–­ï¼‰
        full_text = ""
        async for chunk in self.stream_processor.process(
            messages,
            on_emotion=self._on_emotion_change
        ):
            # æ£€æŸ¥æ˜¯å¦è¢«æ‰“æ–­
            if self.should_interrupt:
                break

            if chunk.is_final:
                await self.send_message({
                    "type": "tts_end",
                    "data": {"full_text": full_text}
                })
            else:
                full_text += chunk.text
                await self.send_message({
                    "type": "tts_chunk",
                    "data": {
                        "text": chunk.text,
                        "audio": base64.b64encode(chunk.audio).decode('utf-8'),
                        "seq": chunk.seq,
                        "is_final": False
                    }
                })

        self.is_processing = False
```

---

### 2.2 å®ç°é™é»˜æ£€æµ‹

**æ–‡ä»¶ï¼š** `frontend/src/hooks/useSilenceDetection.ts`

**åŠŸèƒ½ï¼š**
- æ£€æµ‹ç”¨æˆ·æ˜¯å¦é™é»˜ï¼ˆ5ç§’æ— è¯­éŸ³è¾“å…¥ï¼‰
- è§¦å‘è€³æœµå›¾æ ‡é—ªåŠ¨

**æŠ€æœ¯è§„æ ¼ï¼ˆæ¥è‡ª technical_spec.mdï¼‰ï¼š**
- é™é»˜é˜ˆå€¼ï¼š5ç§’æ— è¯­éŸ³è¾“å…¥
- é—ªåŠ¨é—´éš”ï¼š2ç§’é—ªä¸€æ¬¡
- æ¯ç»„é—ªåŠ¨æ¬¡æ•°ï¼š3æ¬¡ï¼ˆå…±6ç§’ï¼‰
- ç»„é—´é—´éš”ï¼š10ç§’

```typescript
import { useState, useEffect, useRef, useCallback } from 'react';

interface UseSilenceDetectionReturn {
  isSilent: boolean;
  shouldBlink: boolean;
  resetSilenceTimer: () => void;
}

interface SilenceConfig {
  silenceThreshold: number;    // é™é»˜é˜ˆå€¼ï¼ˆæ¯«ç§’ï¼‰
  blinkInterval: number;       // é—ªåŠ¨é—´éš”ï¼ˆæ¯«ç§’ï¼‰
  blinksPerGroup: number;      // æ¯ç»„é—ªåŠ¨æ¬¡æ•°
  groupInterval: number;       // ç»„é—´é—´éš”ï¼ˆæ¯«ç§’ï¼‰
}

const DEFAULT_CONFIG: SilenceConfig = {
  silenceThreshold: 5000,      // 5ç§’
  blinkInterval: 2000,         // 2ç§’
  blinksPerGroup: 3,           // 3æ¬¡
  groupInterval: 10000,        // 10ç§’
};

export const useSilenceDetection = (
  config: SilenceConfig = DEFAULT_CONFIG
): UseSilenceDetectionReturn => {
  const [isSilent, setIsSilent] = useState(false);
  const [shouldBlink, setShouldBlink] = useState(false);

  const silenceTimerRef = useRef<NodeJS.Timeout | null>(null);
  const blinkTimerRef = useRef<NodeJS.Timeout | null>(null);
  const blinkCountRef = useRef(0);
  const lastActivityRef = useRef(Date.now());

  // å¼€å§‹é—ªåŠ¨
  const startBlinking = useCallback(() => {
    blinkCountRef.current = 0;

    const doBlink = () => {
      if (blinkCountRef.current < config.blinksPerGroup) {
        setShouldBlink(true);

        // é—ªåŠ¨æŒç»­æ—¶é—´ï¼ˆ500msï¼‰
        setTimeout(() => setShouldBlink(false), 500);

        blinkCountRef.current++;

        // ä¸‹ä¸€æ¬¡é—ªåŠ¨
        blinkTimerRef.current = setTimeout(doBlink, config.blinkInterval);
      } else {
        // ä¸€ç»„ç»“æŸï¼Œç­‰å¾…ç»„é—´é—´éš”åå¼€å§‹ä¸‹ä¸€ç»„
        blinkCountRef.current = 0;
        blinkTimerRef.current = setTimeout(doBlink, config.groupInterval);
      }
    };

    doBlink();
  }, [config]);

  // åœæ­¢é—ªåŠ¨
  const stopBlinking = useCallback(() => {
    if (blinkTimerRef.current) {
      clearTimeout(blinkTimerRef.current);
      blinkTimerRef.current = null;
    }
    setShouldBlink(false);
    blinkCountRef.current = 0;
  }, []);

  // é‡ç½®é™é»˜è®¡æ—¶å™¨
  const resetSilenceTimer = useCallback(() => {
    lastActivityRef.current = Date.now();

    // åœæ­¢é—ªåŠ¨
    stopBlinking();
    setIsSilent(false);

    // æ¸…é™¤ç°æœ‰è®¡æ—¶å™¨
    if (silenceTimerRef.current) {
      clearTimeout(silenceTimerRef.current);
    }

    // è®¾ç½®æ–°çš„é™é»˜æ£€æµ‹è®¡æ—¶å™¨
    silenceTimerRef.current = setTimeout(() => {
      setIsSilent(true);
      startBlinking();
    }, config.silenceThreshold);
  }, [config.silenceThreshold, startBlinking, stopBlinking]);

  // åˆå§‹åŒ–
  useEffect(() => {
    resetSilenceTimer();

    return () => {
      if (silenceTimerRef.current) {
        clearTimeout(silenceTimerRef.current);
      }
      stopBlinking();
    };
  }, [resetSilenceTimer, stopBlinking]);

  return {
    isSilent,
    shouldBlink,
    resetSilenceTimer,
  };
};
```

---

### 2.3 å®ç°è€³æœµå›¾æ ‡é—ªåŠ¨

**æ–‡ä»¶ï¼š** `frontend/src/components/AvatarArea/EarIndicator.tsx`ï¼ˆæ›´æ–°ï¼‰

```typescript
import React from 'react';
import './EarIndicator.css';

interface EarIndicatorProps {
  isBlinking: boolean;
  visible: boolean;
}

export const EarIndicator: React.FC<EarIndicatorProps> = ({
  isBlinking,
  visible,
}) => {
  if (!visible) {
    return null;
  }

  return (
    <span className={`ear-indicator ${isBlinking ? 'ear-indicator--blinking' : ''}`}>
      ğŸ‘‚
    </span>
  );
};
```

**æ ·å¼ï¼š** `frontend/src/components/AvatarArea/EarIndicator.css`

```css
.ear-indicator {
  position: absolute;
  top: 10%;
  right: 10%;
  font-size: 2rem;
  opacity: 0.8;
  transition: opacity 0.2s ease-in-out;
}

.ear-indicator--blinking {
  animation: ear-blink 0.5s ease-in-out;
}

@keyframes ear-blink {
  0% {
    opacity: 0.8;
    transform: scale(1);
  }
  50% {
    opacity: 1;
    transform: scale(1.2);
  }
  100% {
    opacity: 0.8;
    transform: scale(1);
  }
}

/* å“åº”å¼è°ƒæ•´ */
@media (max-width: 768px) {
  .ear-indicator {
    font-size: 1.5rem;
  }
}
```

**æ›´æ–° AvatarArea ç»„ä»¶ï¼š**

**æ–‡ä»¶ï¼š** `frontend/src/components/AvatarArea/AvatarArea.tsx`ï¼ˆæ›´æ–°ï¼‰

```typescript
import React from 'react';
import { EarIndicator } from './EarIndicator';
import { useSilenceDetection } from '../../hooks/useSilenceDetection';
import './AvatarArea.css';

type EmotionType = 'default' | 'empathy' | 'comfort' | 'happy';

const AVATAR_MAP: Record<EmotionType, string> = {
  default: '/assets/avatars/default.png',
  empathy: '/assets/avatars/empathy.png',
  comfort: '/assets/avatars/comfort.png',
  happy: '/assets/avatars/happy.png',
};

interface AvatarAreaProps {
  emotion: EmotionType;
  isListening: boolean;       // æ˜¯å¦æ­£åœ¨å½•éŸ³
  isAISpeaking: boolean;      // AI æ˜¯å¦æ­£åœ¨è¯´è¯
  onUserActivity: () => void; // ç”¨æˆ·æ´»åŠ¨å›è°ƒ
}

export const AvatarArea: React.FC<AvatarAreaProps> = ({
  emotion,
  isListening,
  isAISpeaking,
  onUserActivity,
}) => {
  const { shouldBlink, resetSilenceTimer } = useSilenceDetection();

  // ç”¨æˆ·æ´»åŠ¨æ—¶é‡ç½®è®¡æ—¶å™¨
  React.useEffect(() => {
    if (isListening) {
      resetSilenceTimer();
    }
  }, [isListening, resetSilenceTimer]);

  // åˆ¤æ–­æ˜¯å¦æ˜¾ç¤ºè€³æœµå›¾æ ‡
  // åªåœ¨ç”¨æˆ·é™é»˜ä¸” AI æ²¡æœ‰è¯´è¯æ—¶æ˜¾ç¤º
  const showEarIndicator = !isListening && !isAISpeaking;

  return (
    <div className="avatar-area">
      <div className="avatar-container">
        <img
          className="avatar-image"
          src={AVATAR_MAP[emotion]}
          alt={`Avatar - ${emotion}`}
        />
        <EarIndicator
          isBlinking={shouldBlink}
          visible={showEarIndicator}
        />
      </div>
    </div>
  );
};
```

---

### 2.4 å®ç°ä¼šè¯å­˜å‚¨ï¼ˆlocalStorageï¼‰

**æ–‡ä»¶ï¼š** `frontend/src/services/storage.ts`

**åŠŸèƒ½ï¼š**
- ä¿å­˜å¯¹è¯å†å²åˆ° localStorage
- é¡µé¢åˆ·æ–°åæ¢å¤å¯¹è¯
- ç®¡ç†ä¸Šä¸‹æ–‡æ•°æ®

```typescript
import { Message } from '../types/conversation';

const STORAGE_KEYS = {
  CONVERSATION_HISTORY: 'mapijing_conversation_history',
  CURRENT_EMOTION: 'mapijing_current_emotion',
  LAST_SESSION_TIME: 'mapijing_last_session_time',
};

// æœ€å¤§å­˜å‚¨æ¡æ•°ï¼ˆé˜²æ­¢ localStorage è¶…é™ï¼‰
const MAX_HISTORY_LENGTH = 100;

export interface ConversationHistory {
  messages: Message[];
  currentEmotion: string;
  lastUpdated: number;
}

export const storage = {
  /**
   * ä¿å­˜å¯¹è¯å†å²
   */
  saveConversation(history: ConversationHistory): void {
    try {
      // é™åˆ¶æ¶ˆæ¯æ•°é‡
      const trimmedMessages = history.messages.slice(-MAX_HISTORY_LENGTH);

      const data: ConversationHistory = {
        messages: trimmedMessages,
        currentEmotion: history.currentEmotion,
        lastUpdated: Date.now(),
      };

      localStorage.setItem(
        STORAGE_KEYS.CONVERSATION_HISTORY,
        JSON.stringify(data)
      );
    } catch (error) {
      console.error('Failed to save conversation:', error);
      // localStorage å¯èƒ½å·²æ»¡ï¼Œå°è¯•æ¸…ç†æ—§æ•°æ®
      this.clearOldData();
    }
  },

  /**
   * åŠ è½½å¯¹è¯å†å²
   */
  loadConversation(): ConversationHistory | null {
    try {
      const data = localStorage.getItem(STORAGE_KEYS.CONVERSATION_HISTORY);
      if (!data) {
        return null;
      }

      const history: ConversationHistory = JSON.parse(data);

      // éªŒè¯æ•°æ®ç»“æ„
      if (!Array.isArray(history.messages)) {
        return null;
      }

      return history;
    } catch (error) {
      console.error('Failed to load conversation:', error);
      return null;
    }
  },

  /**
   * æ·»åŠ å•æ¡æ¶ˆæ¯
   */
  addMessage(message: Message): void {
    const history = this.loadConversation() || {
      messages: [],
      currentEmotion: 'é»˜è®¤é™ªä¼´',
      lastUpdated: Date.now(),
    };

    history.messages.push(message);
    this.saveConversation(history);
  },

  /**
   * æ›´æ–°å½“å‰æƒ…æ„ŸçŠ¶æ€
   */
  updateEmotion(emotion: string): void {
    const history = this.loadConversation();
    if (history) {
      history.currentEmotion = emotion;
      this.saveConversation(history);
    }
  },

  /**
   * æ¸…ç©ºå¯¹è¯å†å²
   */
  clearConversation(): void {
    localStorage.removeItem(STORAGE_KEYS.CONVERSATION_HISTORY);
  },

  /**
   * æ¸…ç†æ—§æ•°æ®ï¼ˆlocalStorage ç©ºé—´ä¸è¶³æ—¶ï¼‰
   */
  clearOldData(): void {
    const history = this.loadConversation();
    if (history && history.messages.length > 10) {
      // ä¿ç•™æœ€è¿‘ 10 æ¡
      history.messages = history.messages.slice(-10);
      this.saveConversation(history);
    }
  },

  /**
   * è·å–å­˜å‚¨ä½¿ç”¨æƒ…å†µ
   */
  getStorageUsage(): { used: number; total: number } {
    let used = 0;
    for (const key in localStorage) {
      if (localStorage.hasOwnProperty(key)) {
        used += localStorage.getItem(key)?.length || 0;
      }
    }
    // localStorage é€šå¸¸é™åˆ¶ä¸º 5MB
    return { used, total: 5 * 1024 * 1024 };
  },
};
```

**ç±»å‹å®šä¹‰ï¼š** `frontend/src/types/conversation.ts`

```typescript
export interface Message {
  id: string;
  role: 'user' | 'assistant';
  content: string;
  timestamp: number;
  emotion?: string;  // ä»… assistant æ¶ˆæ¯æœ‰
}

export interface ConversationState {
  messages: Message[];
  currentEmotion: string;
  isLoading: boolean;
}
```

---

### 2.5 é¡µé¢åˆ·æ–°æ¢å¤ä¼šè¯

**æ–‡ä»¶ï¼š** `frontend/src/hooks/useConversation.ts`ï¼ˆæ›´æ–°ï¼‰

**æ–°å¢åŠŸèƒ½ï¼š**
- é¡µé¢åŠ è½½æ—¶æ¢å¤å¯¹è¯å†å²
- æ¯æ¬¡å¯¹è¯åä¿å­˜åˆ° localStorage

```typescript
import { useState, useEffect, useCallback } from 'react';
import { storage, ConversationHistory } from '../services/storage';
import { Message } from '../types/conversation';
import { v4 as uuidv4 } from 'uuid';

export const useConversation = () => {
  const [messages, setMessages] = useState<Message[]>([]);
  const [currentText, setCurrentText] = useState('');
  const [speaker, setSpeaker] = useState<'user' | 'assistant'>('user');
  const [isStreaming, setIsStreaming] = useState(false);

  const { setEmotionFromServer, emotion } = useEmotion();
  const { onMessage, sendMessage } = useWebSocket();
  const { enqueue, clear: clearAudio, isPlaying } = useAudioPlayer();

  // é¡µé¢åŠ è½½æ—¶æ¢å¤å¯¹è¯
  useEffect(() => {
    const history = storage.loadConversation();
    if (history) {
      setMessages(history.messages);
      setEmotionFromServer(history.currentEmotion);
    }
  }, []);

  // æ·»åŠ ç”¨æˆ·æ¶ˆæ¯
  const addUserMessage = useCallback((text: string) => {
    const message: Message = {
      id: uuidv4(),
      role: 'user',
      content: text,
      timestamp: Date.now(),
    };

    setMessages(prev => {
      const updated = [...prev, message];
      // ä¿å­˜åˆ° localStorage
      storage.saveConversation({
        messages: updated,
        currentEmotion: emotion,
        lastUpdated: Date.now(),
      });
      return updated;
    });
  }, [emotion]);

  // æ·»åŠ åŠ©æ‰‹æ¶ˆæ¯
  const addAssistantMessage = useCallback((text: string, msgEmotion: string) => {
    const message: Message = {
      id: uuidv4(),
      role: 'assistant',
      content: text,
      timestamp: Date.now(),
      emotion: msgEmotion,
    };

    setMessages(prev => {
      const updated = [...prev, message];
      // ä¿å­˜åˆ° localStorage
      storage.saveConversation({
        messages: updated,
        currentEmotion: msgEmotion,
        lastUpdated: Date.now(),
      });
      return updated;
    });
  }, []);

  // å¤„ç† WebSocket æ¶ˆæ¯
  useEffect(() => {
    let currentAssistantText = '';

    const unsubscribe = onMessage((message) => {
      switch (message.type) {
        case 'asr_result':
          setCurrentText(message.data.text);
          setSpeaker('user');
          setIsStreaming(!message.data.is_final);
          break;

        case 'asr_end':
          setCurrentText(message.data.text);
          setSpeaker('user');
          setIsStreaming(false);
          // ä¿å­˜ç”¨æˆ·æ¶ˆæ¯
          addUserMessage(message.data.text);
          break;

        case 'emotion':
          setEmotionFromServer(message.data.emotion);
          storage.updateEmotion(message.data.emotion);
          break;

        case 'tts_chunk':
          if (message.data.seq === 1) {
            currentAssistantText = message.data.text;
            setCurrentText(message.data.text);
          } else {
            currentAssistantText += message.data.text;
            setCurrentText(prev => prev + message.data.text);
          }
          setSpeaker('assistant');
          setIsStreaming(true);

          if (message.data.audio) {
            enqueue({
              audio: message.data.audio,
              seq: message.data.seq,
            });
          }
          break;

        case 'tts_end':
          setIsStreaming(false);
          // ä¿å­˜åŠ©æ‰‹æ¶ˆæ¯ï¼ˆå¦‚æœä¸æ˜¯è¢«æ‰“æ–­çš„ï¼‰
          if (!message.data.interrupted && currentAssistantText) {
            addAssistantMessage(currentAssistantText, emotion);
          }
          currentAssistantText = '';
          break;

        case 'error':
          console.error('Server error:', message.data);
          setIsStreaming(false);
          break;
      }
    });

    return unsubscribe;
  }, [onMessage, enqueue, setEmotionFromServer, addUserMessage, addAssistantMessage, emotion]);

  // æ¸…ç©ºå¯¹è¯å†å²
  const clearHistory = useCallback(() => {
    setMessages([]);
    storage.clearConversation();
  }, []);

  return {
    messages,
    currentText,
    speaker,
    isStreaming,
    isPlaying,
    clearHistory,
  };
};
```

---

### 2.6 åç«¯åŒæ­¥ä¸Šä¸‹æ–‡

**æ–‡ä»¶ï¼š** `backend/api/websocket.py`ï¼ˆæ›´æ–°ï¼‰

**è¯´æ˜ï¼š** åç«¯ä¸ä¿å­˜å¯¹è¯å†å²ï¼Œä½†éœ€è¦åœ¨ WebSocket è¿æ¥æœŸé—´ç»´æŠ¤ä¸Šä¸‹æ–‡ã€‚

```python
class WebSocketHandler:
    async def handle_restore_context(self, messages: list[dict]):
        """
        æ¢å¤å¯¹è¯ä¸Šä¸‹æ–‡ï¼ˆå¯é€‰åŠŸèƒ½ï¼‰

        å¦‚æœéœ€è¦åç«¯ä¹ŸåŒæ­¥å†å²ï¼Œå‰ç«¯å¯ä»¥åœ¨è¿æ¥å»ºç«‹æ—¶å‘é€å†å²æ¶ˆæ¯
        """
        for msg in messages:
            if msg["role"] == "user":
                self.context_manager.add_user_message(msg["content"])
            elif msg["role"] == "assistant":
                self.context_manager.add_assistant_message(msg["content"])
```

**å‰ç«¯è¿æ¥æ—¶æ¢å¤ä¸Šä¸‹æ–‡ï¼ˆå¯é€‰ï¼‰ï¼š**

```typescript
// frontend/src/hooks/useWebSocket.tsï¼ˆæ›´æ–°ï¼‰

const onConnect = useCallback(() => {
  // è¿æ¥å»ºç«‹åï¼Œå‘é€å†å²æ¶ˆæ¯æ¢å¤ä¸Šä¸‹æ–‡
  const history = storage.loadConversation();
  if (history && history.messages.length > 0) {
    sendMessage({
      type: 'restore_context',
      data: {
        messages: history.messages.map(m => ({
          role: m.role,
          content: m.content,
        }))
      }
    });
  }
}, [sendMessage]);
```

---

### 2.7 é”™è¯¯å¤„ç†å®Œå–„

#### 2.7.1 å‰ç«¯é”™è¯¯å¤„ç†

**æ–‡ä»¶ï¼š** `frontend/src/hooks/useErrorHandler.ts`

```typescript
import { useState, useCallback } from 'react';

interface ErrorInfo {
  code: string;
  message: string;
  retryable: boolean;
}

const ERROR_MESSAGES: Record<string, string> = {
  ASR_ERROR: 'è¯­éŸ³è¯†åˆ«æœåŠ¡æš‚æ—¶ä¸å¯ç”¨',
  LLM_ERROR: 'å¯¹è¯æœåŠ¡æš‚æ—¶ä¸å¯ç”¨',
  TTS_ERROR: 'è¯­éŸ³åˆæˆæœåŠ¡æš‚æ—¶ä¸å¯ç”¨',
  NETWORK_ERROR: 'ç½‘ç»œè¿æ¥å¤±è´¥',
  UNKNOWN_ERROR: 'å‘ç”ŸæœªçŸ¥é”™è¯¯',
};

interface UseErrorHandlerReturn {
  error: ErrorInfo | null;
  setError: (error: ErrorInfo | null) => void;
  handleServerError: (errorData: { code: string; message?: string }) => void;
  clearError: () => void;
  retry: () => void;
}

export const useErrorHandler = (
  onRetry?: () => void
): UseErrorHandlerReturn => {
  const [error, setError] = useState<ErrorInfo | null>(null);

  const handleServerError = useCallback((errorData: { code: string; message?: string }) => {
    const message = errorData.message || ERROR_MESSAGES[errorData.code] || ERROR_MESSAGES.UNKNOWN_ERROR;

    setError({
      code: errorData.code,
      message,
      retryable: ['ASR_ERROR', 'LLM_ERROR', 'TTS_ERROR', 'NETWORK_ERROR'].includes(errorData.code),
    });
  }, []);

  const clearError = useCallback(() => {
    setError(null);
  }, []);

  const retry = useCallback(() => {
    clearError();
    onRetry?.();
  }, [clearError, onRetry]);

  return {
    error,
    setError,
    handleServerError,
    clearError,
    retry,
  };
};
```

#### 2.7.2 åç«¯é”™è¯¯å¤„ç†

**æ–‡ä»¶ï¼š** `backend/utils/error_handler.py`

```python
from enum import Enum
from typing import Optional
from dataclasses import dataclass

class ErrorCode(Enum):
    ASR_ERROR = "ASR_ERROR"
    LLM_ERROR = "LLM_ERROR"
    TTS_ERROR = "TTS_ERROR"
    NETWORK_ERROR = "NETWORK_ERROR"
    UNKNOWN_ERROR = "UNKNOWN_ERROR"

@dataclass
class AppError:
    code: ErrorCode
    message: str
    details: Optional[str] = None

def create_error_message(error: AppError) -> dict:
    """åˆ›å»ºé”™è¯¯æ¶ˆæ¯"""
    return {
        "type": "error",
        "data": {
            "code": error.code.value,
            "message": error.message,
        }
    }

# WebSocket å¤„ç†å™¨ä¸­ä½¿ç”¨
async def safe_process(self, coro, error_code: ErrorCode, error_message: str):
    """å®‰å…¨æ‰§è¡Œå¼‚æ­¥æ“ä½œï¼Œæ•è·é”™è¯¯"""
    try:
        return await coro
    except Exception as e:
        error = AppError(
            code=error_code,
            message=error_message,
            details=str(e)
        )
        await self.send_message(create_error_message(error))
        return None
```

---

### 2.8 ä¸»åº”ç”¨æ•´åˆ

**æ–‡ä»¶ï¼š** `frontend/src/App.tsx`ï¼ˆæœ€ç»ˆç‰ˆï¼‰

```typescript
import React from 'react';
import { Layout } from './components/Layout/Layout';
import { AvatarArea } from './components/AvatarArea/AvatarArea';
import { TextArea } from './components/TextArea/TextArea';
import { useConversation } from './hooks/useConversation';
import { useEmotion } from './hooks/useEmotion';
import { useAudioRecorder } from './hooks/useAudioRecorder';
import { useErrorHandler } from './hooks/useErrorHandler';
import './styles/global.css';

const App: React.FC = () => {
  const {
    currentText,
    speaker,
    isStreaming,
    isPlaying,
  } = useConversation();

  const { emotion } = useEmotion();
  const { isRecording, startRecording, stopRecording } = useAudioRecorder();
  const { error, retry, clearError } = useErrorHandler(() => {
    // é‡è¯•é€»è¾‘ï¼šé‡æ–°å¼€å§‹å½•éŸ³
    startRecording();
  });

  // æ˜ å°„æƒ…æ„Ÿç±»å‹
  const emotionType = React.useMemo(() => {
    const map: Record<string, 'default' | 'empathy' | 'comfort' | 'happy'> = {
      'é»˜è®¤é™ªä¼´': 'default',
      'å…±æƒ…å€¾å¬': 'empathy',
      'å®‰æ…°æ”¯æŒ': 'comfort',
      'è½»æ¾æ„‰æ‚¦': 'happy',
    };
    return map[emotion] || 'default';
  }, [emotion]);

  return (
    <Layout
      avatarArea={
        <AvatarArea
          emotion={emotionType}
          isListening={isRecording}
          isAISpeaking={isPlaying}
          onUserActivity={clearError}
        />
      }
      textArea={
        <TextArea
          text={currentText}
          speaker={speaker}
          isStreaming={isStreaming}
          error={error ? {
            message: error.message,
            onRetry: retry,
          } : undefined}
        />
      }
    />
  );
};

export default App;
```

---

## 3. æµ‹è¯•è®¡åˆ’

### 3.1 å•å…ƒæµ‹è¯•

| æµ‹è¯•å¯¹è±¡ | æµ‹è¯•å†…å®¹ | æ–‡ä»¶ |
|----------|----------|------|
| useInterrupt | æ‰“æ–­è§¦å‘é€»è¾‘ | `useInterrupt.test.ts` |
| useSilenceDetection | é™é»˜æ£€æµ‹ã€é—ªåŠ¨æ—¶åº | `useSilenceDetection.test.ts` |
| storage | localStorage è¯»å†™ | `storage.test.ts` |
| useErrorHandler | é”™è¯¯å¤„ç†é€»è¾‘ | `useErrorHandler.test.ts` |

**useSilenceDetection æµ‹è¯•ç”¨ä¾‹ï¼š**
```typescript
import { renderHook, act } from '@testing-library/react';
import { useSilenceDetection } from './useSilenceDetection';

describe('useSilenceDetection', () => {
  beforeEach(() => {
    jest.useFakeTimers();
  });

  afterEach(() => {
    jest.useRealTimers();
  });

  it('should not blink initially', () => {
    const { result } = renderHook(() => useSilenceDetection());
    expect(result.current.shouldBlink).toBe(false);
  });

  it('should start blinking after silence threshold', () => {
    const { result } = renderHook(() => useSilenceDetection({
      silenceThreshold: 5000,
      blinkInterval: 2000,
      blinksPerGroup: 3,
      groupInterval: 10000,
    }));

    // ç­‰å¾… 5 ç§’
    act(() => {
      jest.advanceTimersByTime(5000);
    });

    expect(result.current.isSilent).toBe(true);
  });

  it('should reset on user activity', () => {
    const { result } = renderHook(() => useSilenceDetection());

    // ç­‰å¾…è¿›å…¥é™é»˜çŠ¶æ€
    act(() => {
      jest.advanceTimersByTime(5000);
    });

    expect(result.current.isSilent).toBe(true);

    // é‡ç½®
    act(() => {
      result.current.resetSilenceTimer();
    });

    expect(result.current.isSilent).toBe(false);
    expect(result.current.shouldBlink).toBe(false);
  });
});
```

**storage æµ‹è¯•ç”¨ä¾‹ï¼š**
```typescript
import { storage } from './storage';

describe('storage', () => {
  beforeEach(() => {
    localStorage.clear();
  });

  it('should save and load conversation', () => {
    const history = {
      messages: [
        { id: '1', role: 'user' as const, content: 'ä½ å¥½', timestamp: Date.now() },
      ],
      currentEmotion: 'é»˜è®¤é™ªä¼´',
      lastUpdated: Date.now(),
    };

    storage.saveConversation(history);
    const loaded = storage.loadConversation();

    expect(loaded).not.toBeNull();
    expect(loaded!.messages.length).toBe(1);
    expect(loaded!.messages[0].content).toBe('ä½ å¥½');
  });

  it('should clear conversation', () => {
    storage.saveConversation({
      messages: [],
      currentEmotion: 'é»˜è®¤é™ªä¼´',
      lastUpdated: Date.now(),
    });

    storage.clearConversation();
    const loaded = storage.loadConversation();

    expect(loaded).toBeNull();
  });
});
```

### 3.2 ç«¯åˆ°ç«¯æµ‹è¯•

| æµ‹è¯•åœºæ™¯ | éªŒè¯å†…å®¹ |
|----------|----------|
| å®Œæ•´å¯¹è¯æµç¨‹ | å½•éŸ³ â†’ ASR â†’ LLM â†’ TTS â†’ æ’­æ”¾ å…¨é“¾è·¯ |
| æ‰“æ–­åŠŸèƒ½ | AI è¯´è¯æ—¶ç”¨æˆ·æ‰“æ–­ï¼Œç«‹å³åœæ­¢ |
| é™é»˜é—ªåŠ¨ | 5ç§’æ— æ“ä½œï¼Œè€³æœµå¼€å§‹é—ªåŠ¨ |
| ä¼šè¯æ¢å¤ | åˆ·æ–°é¡µé¢åå¯¹è¯å†å²æ¢å¤ |
| å¤šè½®å¯¹è¯ | è¿ç»­å¤šè½®å¯¹è¯ï¼Œä¸Šä¸‹æ–‡æ­£ç¡® |
| é”™è¯¯æ¢å¤ | æ¨¡æ‹ŸæœåŠ¡ä¸å¯ç”¨ï¼Œæ˜¾ç¤ºé”™è¯¯å¹¶é‡è¯• |

**ç«¯åˆ°ç«¯æµ‹è¯•è„šæœ¬ï¼š**
```bash
# 1. å¯åŠ¨åç«¯
cd backend
uvicorn main:app --reload --port 8000

# 2. å¯åŠ¨å‰ç«¯
cd frontend
npm run dev

# 3. æµè§ˆå™¨æ‰‹å·¥æµ‹è¯•

# æµ‹è¯• 1: å®Œæ•´å¯¹è¯æµç¨‹
# - æ‰“å¼€é¡µé¢
# - å…è®¸éº¦å…‹é£æƒé™
# - è¯´ "ä½ å¥½"
# - éªŒè¯ï¼š
#   - çœ‹åˆ° "ä½ å¥½" æ–‡å­—
#   - æ”¶åˆ° AI å›å¤ï¼ˆæ–‡å­—+è¯­éŸ³åŒæ­¥ï¼‰
#   - å¤´åƒæ ¹æ®æƒ…æ„Ÿåˆ‡æ¢

# æµ‹è¯• 2: æ‰“æ–­åŠŸèƒ½
# - è¯´ä¸€å¥è¯ï¼Œç­‰å¾… AI å›å¤
# - AI å›å¤è¿‡ç¨‹ä¸­å†æ¬¡è¯´è¯
# - éªŒè¯ï¼š
#   - AI è¯­éŸ³ç«‹å³åœæ­¢
#   - å¼€å§‹è¯†åˆ«æ–°çš„è¯­éŸ³è¾“å…¥

# æµ‹è¯• 3: é™é»˜æ£€æµ‹
# - åœæ­¢è¯´è¯ï¼Œç­‰å¾… 5 ç§’
# - éªŒè¯ï¼š
#   - è€³æœµå›¾æ ‡å¼€å§‹é—ªåŠ¨
#   - é—ªåŠ¨æ¨¡å¼ï¼š2ç§’ä¸€æ¬¡ï¼Œ3æ¬¡ä¸ºä¸€ç»„
# - å†æ¬¡è¯´è¯
# - éªŒè¯ï¼šé—ªåŠ¨ç«‹å³åœæ­¢

# æµ‹è¯• 4: ä¼šè¯æ¢å¤
# - è¿›è¡Œå‡ è½®å¯¹è¯
# - åˆ·æ–°é¡µé¢
# - éªŒè¯ï¼š
#   - å¯¹è¯å†å²æ¢å¤
#   - æƒ…æ„ŸçŠ¶æ€æ¢å¤
#   - å¯ä»¥ç»§ç»­å¯¹è¯

# æµ‹è¯• 5: é”™è¯¯å¤„ç†
# - æ–­å¼€åç«¯æœåŠ¡
# - å°è¯•è¯´è¯
# - éªŒè¯ï¼š
#   - æ˜¾ç¤ºé”™è¯¯æç¤º
#   - æ˜¾ç¤ºé‡è¯•æŒ‰é’®
# - æ¢å¤åç«¯æœåŠ¡
# - ç‚¹å‡»é‡è¯•
# - éªŒè¯ï¼šåŠŸèƒ½æ¢å¤æ­£å¸¸
```

---

## 4. äº¤ä»˜ç‰©

å®Œæˆæœ¬é˜¶æ®µåï¼Œåº”å…·å¤‡ï¼š

- [ ] `frontend/src/hooks/useInterrupt.ts` - æ‰“æ–­åŠŸèƒ½ Hook
- [ ] `frontend/src/hooks/useSilenceDetection.ts` - é™é»˜æ£€æµ‹ Hook
- [ ] `frontend/src/services/storage.ts` - localStorage å°è£…
- [ ] `frontend/src/hooks/useErrorHandler.ts` - é”™è¯¯å¤„ç† Hook
- [ ] `backend/utils/error_handler.py` - åç«¯é”™è¯¯å¤„ç†
- [ ] æ‰“æ–­åŠŸèƒ½æ­£å¸¸å·¥ä½œ
- [ ] é™é»˜æ£€æµ‹è§¦å‘è€³æœµé—ªåŠ¨
- [ ] ä¼šè¯åˆ·æ–°åå¯æ¢å¤
- [ ] é”™è¯¯æç¤ºå’Œé‡è¯•åŠŸèƒ½
- [ ] ç«¯åˆ°ç«¯å®Œæ•´æµç¨‹æµ‹è¯•é€šè¿‡
- [ ] å•å…ƒæµ‹è¯•å…¨éƒ¨é€šè¿‡

---

## 5. é¢„è®¡äº§å‡ºæ–‡ä»¶

```
frontend/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ hooks/
â”‚   â”‚   â”œâ”€â”€ useInterrupt.ts          # æ–°å¢
â”‚   â”‚   â”œâ”€â”€ useSilenceDetection.ts   # æ–°å¢
â”‚   â”‚   â”œâ”€â”€ useErrorHandler.ts       # æ–°å¢
â”‚   â”‚   â”œâ”€â”€ useConversation.ts       # æ›´æ–°
â”‚   â”‚   â””â”€â”€ useAudioRecorder.ts      # æ›´æ–°
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â””â”€â”€ storage.ts               # æ–°å¢
â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”œâ”€â”€ AvatarArea/
â”‚   â”‚   â”‚   â”œâ”€â”€ AvatarArea.tsx       # æ›´æ–°
â”‚   â”‚   â”‚   â”œâ”€â”€ EarIndicator.tsx     # æ›´æ–°
â”‚   â”‚   â”‚   â””â”€â”€ EarIndicator.css     # æ›´æ–°
â”‚   â”‚   â””â”€â”€ TextArea/
â”‚   â”‚       â””â”€â”€ TextArea.tsx         # æ›´æ–°
â”‚   â”œâ”€â”€ types/
â”‚   â”‚   â””â”€â”€ conversation.ts          # æ–°å¢
â”‚   â””â”€â”€ App.tsx                      # æ›´æ–°
â”‚
â”œâ”€â”€ __tests__/
â”‚   â”œâ”€â”€ useInterrupt.test.ts         # æ–°å¢
â”‚   â”œâ”€â”€ useSilenceDetection.test.ts  # æ–°å¢
â”‚   â”œâ”€â”€ storage.test.ts              # æ–°å¢
â”‚   â””â”€â”€ useErrorHandler.test.ts      # æ–°å¢

backend/
â”œâ”€â”€ api/
â”‚   â””â”€â”€ websocket.py                 # æ›´æ–°
â””â”€â”€ utils/
    â””â”€â”€ error_handler.py             # æ–°å¢
```

---

## 6. é¡¹ç›®å®Œæˆæ£€æŸ¥æ¸…å•

å®Œæˆæ‰€æœ‰é˜¶æ®µåï¼Œè¿›è¡Œæœ€ç»ˆæ£€æŸ¥ï¼š

### 6.1 åŠŸèƒ½æ£€æŸ¥

| åŠŸèƒ½ | çŠ¶æ€ |
|------|------|
| å“åº”å¼å¸ƒå±€ï¼ˆæ‰‹æœº/ç”µè„‘ï¼‰ | [ ] |
| è™šæ‹Ÿäººå¤´åƒå±•ç¤ºï¼ˆ4ç§çŠ¶æ€ï¼‰ | [ ] |
| æƒ…æ„ŸçŠ¶æ€åˆ‡æ¢ | [ ] |
| è¯­éŸ³å½•éŸ³ + PCM é‡‡é›† | [ ] |
| ASR æµå¼è¯†åˆ« | [ ] |
| LLM å¯¹è¯ï¼ˆå¤šè½®ä¸Šä¸‹æ–‡ï¼‰ | [ ] |
| TTS è¯­éŸ³åˆæˆ | [ ] |
| æ–‡å­—éŸ³é¢‘åŒæ­¥å±•ç¤º | [ ] |
| æ‰“æ–­åŠŸèƒ½ | [ ] |
| é™é»˜æ£€æµ‹ + è€³æœµé—ªåŠ¨ | [ ] |
| ä¼šè¯å­˜å‚¨å’Œæ¢å¤ | [ ] |
| é”™è¯¯æç¤ºå’Œé‡è¯• | [ ] |

### 6.2 æŠ€æœ¯æŒ‡æ ‡æ£€æŸ¥

| æŒ‡æ ‡ | è¦æ±‚ | çŠ¶æ€ |
|------|------|------|
| ä¸Šä¸‹æ–‡é•¿åº¦é™åˆ¶ | 50k tokens | [ ] |
| é™é»˜é˜ˆå€¼ | 5ç§’ | [ ] |
| é—ªåŠ¨é—´éš” | 2ç§’ | [ ] |
| æ¯ç»„é—ªåŠ¨æ¬¡æ•° | 3æ¬¡ | [ ] |
| ç»„é—´é—´éš” | 10ç§’ | [ ] |
| éŸ³é¢‘æ ¼å¼ï¼ˆä¸Šè¡Œï¼‰ | PCM 16bit 16kHz | [ ] |
| éŸ³é¢‘æ ¼å¼ï¼ˆä¸‹è¡Œï¼‰ | MP3 | [ ] |

### 6.3 æµ‹è¯•æ£€æŸ¥

| æµ‹è¯•ç±»å‹ | çŠ¶æ€ |
|----------|------|
| å‰ç«¯å•å…ƒæµ‹è¯•å…¨éƒ¨é€šè¿‡ | [ ] |
| åç«¯å•å…ƒæµ‹è¯•å…¨éƒ¨é€šè¿‡ | [ ] |
| ç«¯åˆ°ç«¯å®Œæ•´æµç¨‹æµ‹è¯• | [ ] |
| å“åº”å¼å¸ƒå±€æµ‹è¯•ï¼ˆæ‰‹æœº/ç”µè„‘ï¼‰ | [ ] |
| é•¿æ—¶é—´è¿è¡Œç¨³å®šæ€§æµ‹è¯• | [ ] |

---

## 7. æ³¨æ„äº‹é¡¹

### 7.1 æ‰“æ–­åŠŸèƒ½æ³¨æ„ç‚¹
- æ£€æµ‹ç”¨æˆ·è¯­éŸ³éœ€è¦æœ‰é˜ˆå€¼ï¼Œé¿å…å™ªéŸ³è¯¯è§¦å‘
- æ‰“æ–­åéœ€è¦ç­‰å¾…ä¸€å°æ®µæ—¶é—´æ‰èƒ½å†æ¬¡æ‰“æ–­
- åç«¯æ”¶åˆ°æ‰“æ–­åè¦ç«‹å³åœæ­¢å¤„ç†

### 7.2 é™é»˜æ£€æµ‹æ³¨æ„ç‚¹
- AI è¯´è¯æ—¶ä¸è®¡å…¥é™é»˜æ—¶é—´
- ç”¨æˆ·å½•éŸ³æ—¶é‡ç½®é™é»˜è®¡æ—¶å™¨
- é—ªåŠ¨åŠ¨ç”»è¦å¹³æ»‘ï¼Œä¸èƒ½çªå…€

### 7.3 localStorage æ³¨æ„ç‚¹
- 5MB é™åˆ¶ï¼Œéœ€è¦æ§åˆ¶å­˜å‚¨å¤§å°
- å­˜å‚¨å¤±è´¥æ—¶è¦æœ‰é™çº§å¤„ç†
- æ•°æ®æ ¼å¼ç‰ˆæœ¬åŒ–ï¼Œä¾¿äºåç»­å‡çº§

### 7.4 æµè§ˆå™¨å…¼å®¹æ€§
- AudioContext éœ€è¦ç”¨æˆ·äº¤äº’ååˆ›å»º
- éº¦å…‹é£æƒé™åœ¨é HTTPS ä¸‹å¯èƒ½å—é™
- æµ‹è¯•ä¸»æµæµè§ˆå™¨ï¼ˆChromeã€Firefoxã€Safariï¼‰
