# 技术规格书

> 版本：1.0
> 更新日期：2026-02-07

## 项目概述
这是一个基于 Web 的聊天虚拟人应用，提供语音聊天功能，目的是给用户提供情绪价值，帮助用户获得良好的情绪感受。

---

## 1. 前端技术栈

### 1.1 框架选型：React

| 项目 | 选择 |
|------|------|
| 框架 | React 18+ |
| 语言 | TypeScript |
| 样式方案 | CSS Modules 或 Tailwind CSS（响应式布局） |
| 状态管理 | React 内置 useState/useContext（无需 Redux） |

**选型理由：**
- 组件化适配手机/电脑两种布局
- 状态管理清晰，适合处理虚拟人表情状态（4种）、文字流式输出、语音状态等
- 流式渲染友好，虚拟DOM和状态更新机制效率高
- 生态成熟，音频录制、WebSocket 等有成熟库支持

### 1.2 离线功能
- **不支持离线**，不使用 PWA

### 1.3 浏览器端存储

| 存储内容 | 存储方式 | 说明 |
|----------|----------|------|
| 用户偏好设置 | localStorage | 简单键值对 |
| 聊天历史记录 | localStorage | 文字形式存储，不限制条数 |

**说明：**
- 用户清除浏览器数据后记录丢失，可接受
- 不需要用户认证系统

---

## 2. 后端技术栈

### 2.1 框架选型：Python + FastAPI

| 项目 | 选择 |
|------|------|
| 语言 | Python 3.10+ |
| 框架 | FastAPI |
| ASGI服务器 | uvicorn |
| HTTP客户端 | httpx（异步，调用 DeepSeek API） |
| 流式通信 | WebSocket |

**选型理由：**
- Python 生态中 LLM 相关库最丰富，DeepSeek API 调用、流式响应处理方便
- FastAPI 原生支持 async/await，适合处理流式语音识别、流式 TTS 输出、WebSocket 长连接
- 与参考工程 `ScriptBuddy` 技术栈一致，便于复用代码

### 2.2 用户认证
- **不需要**用户认证系统
- 用户信息和聊天记录存储在浏览器端

---

## 3. 语音相关

### 3.1 录音技术：Web Audio API

**选型理由：**
- 需要实时流式传输原始 PCM 数据
- 可自定义降采样（浏览器 44.1/48kHz → 16kHz）
- 更精细的音频控制

**技术流程：**
```
navigator.mediaDevices.getUserMedia()
    → AudioContext
    → ScriptProcessorNode
    → 降采样(16kHz) + 格式转换(Float32→Int16 PCM)
    → WebSocket 发送
```

**音频参数：**

| 参数 | 值 |
|------|-----|
| 格式 | PCM |
| 采样率 | 16kHz |
| 位深 | 16bit |
| 声道 | 单声道 |

### 3.2 语音识别（ASR）

| 项目 | 方案 |
|------|------|
| 传输方式 | **实时流式** |
| 通信协议 | WebSocket |
| 服务商 | 火山引擎（豆包大模型 ASR） |
| 架构 | 浏览器 ↔ FastAPI代理 ↔ 火山引擎 |

**架构说明：**
- 浏览器不直接连接火山引擎，通过后端代理转发
- 后端代理负责注入 API 凭证，保护敏感信息
- 双向 WebSocket 透传音频数据和识别结果

### 3.3 文字转语音（TTS）

| 项目 | 方案 |
|------|------|
| 通信协议 | WebSocket |
| 服务商 | 火山引擎（豆包语音合成） |
| 音频格式 | MP3 |
| 播放方式 | Web Audio API（decodeAudioData + BufferSource） |

### 3.4 静默检测与耳朵图标提示

**静默判定：**

| 参数 | 值 |
|------|-----|
| 静默阈值 | 5秒无语音输入 |

**耳朵图标闪动规则：**

| 参数 | 值 |
|------|-----|
| 闪动间隔 | 2秒闪一次 |
| 每组闪动次数 | 3次（共6秒） |
| 组间间隔 | 10秒 |

**行为逻辑：**
```
用户静默 5秒
    → 开始第1组闪动（2秒间隔闪3次，持续6秒）
    → 等待 10秒
    → 开始第2组闪动
    → 循环直到用户说话

用户开始说话
    → 立即停止闪动
    → 重置计时器
```

---

## 4. 接口协议

### 4.1 流式协议：WebSocket

**选型理由：**

| 对比项 | WebSocket | SSE |
|--------|-----------|-----|
| 双向通信 | ✓ 支持 | ✗ 仅服务端推送 |
| 音频流传输 | ✓ 支持二进制 | ✗ 仅文本 |
| 连接复用 | ✓ 一个连接处理全流程 | 需要多个连接 |

**统一 WebSocket 连接架构：**
```
浏览器 ←──WebSocket──→ FastAPI 后端
                          ├─→ 火山引擎 ASR（语音识别）
                          ├─→ DeepSeek API（LLM对话）
                          └─→ 火山引擎 TTS（语音合成）
```

**对话流程：**
1. 用户语音 → 后端 → ASR识别 → 识别结果返回前端
2. 识别完成 → 后端调用LLM → 流式文字返回前端
3. LLM返回 → 后端调用TTS → 流式音频返回前端

### 4.2 语音数据格式

| 方向 | 格式 | 理由 |
|------|------|------|
| 上行（录音→ASR） | PCM 16bit 16kHz | 火山引擎 ASR 要求，无压缩延迟最低 |
| 下行（TTS→播放） | MP3 | 压缩率高，节省带宽；浏览器原生支持解码 |

**说明：**
- PCM 上行：虽然数据量大，但实时性要求高，压缩会增加延迟
- MP3 下行：TTS 音频可接受轻微延迟，压缩后传输更快

### 4.3 错误处理机制

| 场景 | 处理方式 |
|------|----------|
| 接口调用出错 | 文字区域显示红色错误提示 + 重试按钮 |
| 用户点击重试 | 重新发起请求 |
| 网络断开 | 显示错误提示，**不自动重连** |

**错误提示样式：**
- 红色文字显示错误信息
- 提供"重试"按钮
- 用户点击后重新发起请求

### 4.4 WebSocket 消息格式定义

#### 4.4.1 消息类型枚举

| 类型 | 方向 | 说明 |
|------|------|------|
| `audio_data` | 客户端→服务端 | 用户语音 PCM 数据 |
| `audio_end` | 客户端→服务端 | 用户语音结束标记 |
| `interrupt` | 客户端→服务端 | 用户打断（停止 TTS 播放） |
| `asr_result` | 服务端→客户端 | ASR 识别结果（流式） |
| `asr_end` | 服务端→客户端 | ASR 识别完成 |
| `tts_chunk` | 服务端→客户端 | TTS 文字+音频同步片段（流式） |
| `tts_end` | 服务端→客户端 | TTS 播放完成 |
| `emotion` | 服务端→客户端 | 情感状态变更 |
| `error` | 服务端→客户端 | 错误信息 |

**设计说明：** 为实现文字和语音同步展示，采用 `tts_chunk` 消息将 LLM 回复文字和对应 TTS 音频**绑定在一起**按片段下发，前端收到后同时展示文字和播放音频。

#### 4.4.2 消息格式

**文本消息格式（JSON）：**

```json
{
  "type": "消息类型",
  "data": { ... },
  "timestamp": 1234567890
}
```

**二进制消息格式（音频数据）：**

```
+--------+--------+------------------+
| 1 byte | 4 bytes|    N bytes       |
| type   | length |    payload       |
+--------+--------+------------------+
```

- `type`: 消息类型标识（0x01=audio_data, 0x02=tts_audio）
- `length`: payload 长度（大端序）
- `payload`: 音频二进制数据

#### 4.4.3 详细消息定义

**1. 客户端发送音频数据**
```json
{
  "type": "audio_data",
  "data": {
    "audio": "<base64 encoded PCM>",
    "seq": 1
  }
}
```
或使用二进制格式直接发送 PCM 数据。

**2. 客户端发送语音结束**
```json
{
  "type": "audio_end",
  "data": {}
}
```

**3. 客户端发送打断请求**
```json
{
  "type": "interrupt",
  "data": {}
}
```

**4. 服务端返回 ASR 识别结果（流式）**
```json
{
  "type": "asr_result",
  "data": {
    "text": "你好",
    "is_final": false
  }
}
```

**5. 服务端返回 ASR 识别完成**
```json
{
  "type": "asr_end",
  "data": {
    "text": "你好，我今天心情不太好"
  }
}
```

**6. 服务端返回 TTS 文字+音频同步片段（流式）**

LLM 回复按句子/片段切分，每个片段同时包含文字和对应的 TTS 音频，实现文字和语音同步展示：

```json
{
  "type": "tts_chunk",
  "data": {
    "text": "我理解你的感受，",
    "audio": "<base64 encoded MP3>",
    "seq": 1,
    "is_final": false
  }
}
```

| 字段 | 说明 |
|------|------|
| `text` | 当前片段的文字内容 |
| `audio` | 当前片段对应的 MP3 音频（Base64 编码） |
| `seq` | 片段序号，从 1 开始 |
| `is_final` | 是否为最后一个片段 |

**后端处理逻辑：**
1. LLM 流式输出文字，按句子/标点切分
2. 每个句子立即调用 TTS 转换为音频
3. 文字和音频绑定在一起下发

**前端处理逻辑：**
1. 收到 `tts_chunk` 后立即追加文字到显示区域
2. 音频加入播放队列
3. 按顺序播放音频，实现文字和语音同步

**7. 服务端返回 TTS 完成**
```json
{
  "type": "tts_end",
  "data": {
    "full_text": "我理解你的感受，能告诉我发生了什么吗？"
  }
}
```

| 字段 | 说明 |
|------|------|
| `full_text` | 本轮回复的完整文字（用于校验/存储） |

**8. 服务端返回情感状态**
```json
{
  "type": "emotion",
  "data": {
    "emotion": "共情倾听"
  }
}
```
情感值：`默认陪伴` | `共情倾听` | `安慰支持` | `轻松愉悦`

**9. 服务端返回错误**
```json
{
  "type": "error",
  "data": {
    "code": "ASR_ERROR",
    "message": "语音识别服务暂时不可用"
  }
}
```

错误码枚举：

| 错误码 | 说明 |
|--------|------|
| `ASR_ERROR` | 语音识别错误 |
| `LLM_ERROR` | 大模型调用错误 |
| `TTS_ERROR` | 语音合成错误 |
| `NETWORK_ERROR` | 网络连接错误 |
| `UNKNOWN_ERROR` | 未知错误 |

#### 4.4.4 完整对话流程时序

```
客户端                              服务端
  │                                    │
  │──── [WebSocket 连接建立] ────────→│
  │                                    │
  │══════════ 用户说话阶段 ═══════════│
  │                                    │
  │──── audio_data (PCM) ────────────→│
  │──── audio_data (PCM) ────────────→│
  │←─── asr_result (流式识别) ────────│  → 前端实时显示识别文字
  │──── audio_data (PCM) ────────────→│
  │←─── asr_result (流式识别) ────────│
  │──── audio_end ───────────────────→│
  │←─── asr_end (识别完成) ───────────│
  │                                    │
  │══════════ AI 回复阶段 ════════════│
  │                                    │
  │←─── emotion (共情倾听) ───────────│  → 前端切换头像
  │                                    │
  │←─── tts_chunk ────────────────────│  → 片段1: 文字"我理解" + 音频
  │     { text + audio, seq=1 }        │     前端: 显示文字 + 播放音频
  │                                    │
  │←─── tts_chunk ────────────────────│  → 片段2: 文字"你的感受，" + 音频
  │     { text + audio, seq=2 }        │     前端: 追加文字 + 队列播放
  │                                    │
  │←─── emotion (安慰支持) ───────────│  → 前端切换头像
  │                                    │
  │←─── tts_chunk ────────────────────│  → 片段3: 文字"能告诉我..." + 音频
  │     { text + audio, seq=3 }        │     前端: 追加文字 + 队列播放
  │                                    │
  │←─── tts_end ──────────────────────│  → 回复完成
  │     { full_text }                  │     前端: 存储完整对话
  │                                    │
  │══════════ 用户打断场景 ════════════│
  │                                    │
  │ [用户开始说话，触发打断]            │
  │──── interrupt ───────────────────→│  → 前端: 停止音频播放
  │←─── tts_end (强制结束) ───────────│  → 后端: 停止 TTS 生成
  │                                    │
  │──── audio_data (PCM) ────────────→│  → 开始新一轮 ASR
  │     ...                            │
```

#### 4.4.5 文字音频同步机制

**核心设计：** 文字和音频绑定在 `tts_chunk` 中同步下发，确保用户看到的文字和听到的语音一致。

**前端播放队列实现：**

```
收到 tts_chunk(seq=1) → 显示文字1 → 音频1入队 → 开始播放音频1
收到 tts_chunk(seq=2) → 显示文字2 → 音频2入队 → (等待音频1播放完)
收到 tts_chunk(seq=3) → 显示文字3 → 音频3入队 → (等待音频2播放完)
...
音频1播放完 → 播放音频2
音频2播放完 → 播放音频3
...
```

**打断处理：**
1. 用户开始说话 → 前端检测到语音输入
2. 前端立即停止当前音频播放，清空播放队列
3. 前端发送 `interrupt` 消息
4. 后端停止 LLM/TTS 处理，返回 `tts_end`
5. 开始新一轮 ASR 识别

---

## 5. 虚拟人头像

### 5.1 图片来源
- 四张头像图片**已有**（默认陪伴、共情倾听、安慰支持、轻松愉悦）

### 5.2 图片展示规则

| 项目 | 规则 |
|------|------|
| 尺寸适配 | 按现有图片尺寸，**等比缩放**占满当前区域 |
| 背景 | 无背景（透明或纯色均可） |
| 切换动画 | **无过渡动画**，直接切换 |

### 5.3 头像状态与情感映射

| 情感状态 | 对应头像 | 触发场景 |
|----------|----------|----------|
| 默认陪伴 | 头像1 | 默认状态、等待用户说话 |
| 共情倾听 | 头像2 | 用户倾诉时 |
| 安慰支持 | 头像3 | 安慰用户时 |
| 轻松愉悦 | 头像4 | 轻松聊天、开心时 |

### 5.4 耳朵图标

| 项目 | 规则 |
|------|------|
| 图标 | 使用 emoji 耳朵 👂 |
| 位置 | 头像图片的**右上角**（非区域右上角） |
| 触发 | 用户静默 5 秒后开始闪动 |

---

## 6. 会话管理

### 6.1 对话历史

| 项目 | 规则 |
|------|------|
| 服务端保存 | **不保留**对话历史 |
| 浏览器端保存 | 使用 localStorage 保存（用户刷新后可恢复） |

### 6.2 多轮对话上下文

| 项目 | 规则 |
|------|------|
| 上下文长度限制 | 总长度不超过 **50k** tokens |
| 策略说明 | 此限制后续可能调整 |
| 超限处理 | 截断早期对话，保留最近内容 |

### 6.3 页面刷新

| 场景 | 行为 |
|------|------|
| 用户刷新页面 | **保留**会话，从 localStorage 恢复 |
| 用户清除浏览器数据 | 会话丢失，可接受 |

---

## 7. 部署相关

### 7.1 部署环境

| 项目 | 选择 |
|------|------|
| 环境 | **云服务器** |
| 容器化 | 暂不要求 |

### 7.2 HTTPS

| 项目 | 说明 |
|------|------|
| 是否需要 | **不需要**，目前无 HTTPS |
| 开发测试 | 使用 localhost（浏览器允许 localhost 访问麦克风） |
| 生产环境 | 需通过 HTTP 访问，注意部分浏览器可能限制麦克风权限 |

**注意：** 部分浏览器（如 Chrome）在非 HTTPS 环境下可能阻止麦克风访问。如遇此问题，可考虑：
- 使用 Firefox（对 HTTP 限制较宽松）
- 后续添加 HTTPS 支持

### 7.3 并发用户数

| 项目 | 值 |
|------|-----|
| 预期并发 | **1 个用户** |
| 说明 | 不考虑高并发场景 |

---

## 8. 其他功能

### 8.1 打断功能

| 项目 | 规则 |
|------|------|
| 是否支持 | **是** |
| 行为 | 用户开始说话时，立即停止 AI 语音播放 |
| 实现 | 检测到用户语音输入 → 停止 TTS 播放 → 开始 ASR 识别 |

### 8.2 网络异常处理

| 场景 | 处理方式 |
|------|----------|
| 网络异常 | 直接按**报错处理** |
| 降级策略 | 无，不做特殊降级 |
| 用户操作 | 显示错误提示 + 重试按钮 |

### 8.3 输入方式

| 项目 | 规则 |
|------|------|
| 语音输入 | **唯一**输入方式 |
| 文字输入 | **不支持** |

---

## 9. 项目目录结构

```
Mapijing/
├── doc/                              # 文档目录
│   ├── requirement.md                # 需求文档
│   └── technical_spec.md             # 技术规格书
│
├── frontend/                         # 前端项目（React）
│   ├── public/
│   │   ├── index.html
│   │   └── assets/
│   │       └── avatars/              # 虚拟人头像图片
│   │           ├── default.png       # 默认陪伴
│   │           ├── empathy.png       # 共情倾听
│   │           ├── comfort.png       # 安慰支持
│   │           └── happy.png         # 轻松愉悦
│   │
│   ├── src/
│   │   ├── index.tsx                 # 入口文件
│   │   ├── App.tsx                   # 主应用组件
│   │   │
│   │   ├── components/               # UI 组件
│   │   │   ├── AvatarArea/           # 虚拟人区域
│   │   │   │   ├── AvatarArea.tsx
│   │   │   │   ├── AvatarArea.css
│   │   │   │   └── EarIndicator.tsx  # 耳朵闪动图标
│   │   │   │
│   │   │   ├── TextArea/             # 文字区域
│   │   │   │   ├── TextArea.tsx
│   │   │   │   ├── TextArea.css
│   │   │   │   └── ErrorDisplay.tsx  # 错误提示组件
│   │   │   │
│   │   │   └── Layout/               # 布局组件
│   │   │       ├── MobileLayout.tsx  # 手机布局
│   │   │       └── DesktopLayout.tsx # 电脑布局
│   │   │
│   │   ├── hooks/                    # 自定义 Hooks
│   │   │   ├── useWebSocket.ts       # WebSocket 连接管理
│   │   │   ├── useAudioRecorder.ts   # 录音管理
│   │   │   ├── useAudioPlayer.ts     # 音频播放管理
│   │   │   ├── useSilenceDetection.ts# 静默检测
│   │   │   └── useConversation.ts    # 对话状态管理
│   │   │
│   │   ├── services/                 # 服务层
│   │   │   ├── websocket.ts          # WebSocket 客户端
│   │   │   ├── audioProcessor.ts     # 音频处理（降采样、格式转换）
│   │   │   └── storage.ts            # localStorage 封装
│   │   │
│   │   ├── types/                    # TypeScript 类型定义
│   │   │   ├── message.ts            # WebSocket 消息类型
│   │   │   ├── emotion.ts            # 情感状态类型
│   │   │   └── conversation.ts       # 对话相关类型
│   │   │
│   │   ├── utils/                    # 工具函数
│   │   │   └── responsive.ts         # 响应式布局工具
│   │   │
│   │   └── styles/                   # 全局样式
│   │       └── global.css
│   │
│   ├── package.json
│   ├── tsconfig.json
│   └── vite.config.ts                # 使用 Vite 构建
│
├── backend/                          # 后端项目（FastAPI）
│   ├── main.py                       # FastAPI 入口
│   │
│   ├── api/                          # API 路由
│   │   ├── __init__.py
│   │   └── websocket.py              # WebSocket 端点
│   │
│   ├── services/                     # 业务服务
│   │   ├── __init__.py
│   │   ├── asr_service.py            # ASR 服务（火山引擎代理）
│   │   ├── tts_service.py            # TTS 服务（火山引擎代理）
│   │   ├── llm_service.py            # LLM 服务（DeepSeek API）
│   │   └── conversation_service.py   # 对话管理服务
│   │
│   ├── models/                       # 数据模型
│   │   ├── __init__.py
│   │   └── message.py                # WebSocket 消息模型
│   │
│   ├── utils/                        # 工具函数
│   │   ├── __init__.py
│   │   └── protocol.py               # 火山引擎协议封装
│   │
│   ├── config/                       # 配置
│   │   ├── __init__.py
│   │   └── settings.py               # 配置项（API Key 等）
│   │
│   ├── requirements.txt              # Python 依赖
│   └── .env.example                  # 环境变量示例
│
└── README.md                         # 项目说明
```

### 9.1 前端核心模块说明

| 模块 | 职责 |
|------|------|
| `components/AvatarArea` | 虚拟人头像展示、耳朵图标闪动 |
| `components/TextArea` | 文字流式展示、错误提示 |
| `components/Layout` | 响应式布局（手机/电脑） |
| `hooks/useWebSocket` | WebSocket 连接、重连、消息收发 |
| `hooks/useAudioRecorder` | 麦克风录音、PCM 数据采集 |
| `hooks/useAudioPlayer` | MP3 音频播放、打断控制 |
| `hooks/useSilenceDetection` | 静默检测、耳朵闪动触发 |
| `services/audioProcessor` | 降采样、Float32→Int16 转换 |
| `services/storage` | 对话历史 localStorage 存取 |

### 9.2 后端核心模块说明

| 模块 | 职责 |
|------|------|
| `api/websocket` | WebSocket 端点，处理客户端连接 |
| `services/asr_service` | 连接火山引擎 ASR，转发音频流 |
| `services/tts_service` | 连接火山引擎 TTS，获取音频流 |
| `services/llm_service` | 调用 DeepSeek API，解析回复 |
| `services/conversation_service` | 管理对话上下文、情感解析 |
| `utils/protocol` | 火山引擎二进制协议封装 |
| `config/settings` | API Key、服务地址等配置 |

---

## 参考资源

| 资源 | 路径 |
|------|------|
| 参考代码工程 | `../ScriptBuddy/` |
| 语音配置文档 | `../ScriptBuddy/doc/TTS_ASR_Configuration_Guide.md` |
